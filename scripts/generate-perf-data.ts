#!/usr/bin/env bun
/**
 * Complete Performance Pipeline for paths-le
 *
 * Run with: bun run scripts/generate-perf-data.ts
 *
 * This script:
 * 1. Generates test data files (100KB to 30MB)
 * 2. Runs performance benchmarks
 * 3. Updates docs/PERFORMANCE.md
 * 4. Updates README.md performance table
 */

import { execSync } from 'node:child_process'
import { readFileSync, writeFileSync } from 'node:fs'
import { join } from 'node:path'

interface FileSpec {
  readonly name: string
  readonly targetSizeMB: number
  readonly format: 'json' | 'csv' | 'html' | 'toml' | 'javascript'
}

// File specifications for realistic testing
// Based on extension safety thresholds: 1MB warning, 10MB error, 30MB practical limit
const FILE_SPECS: readonly FileSpec[] = Object.freeze([
  // Small files (100KB - 1MB) - typical daily use
  { name: '100kb.json', targetSizeMB: 0.1, format: 'json' },
  { name: '500kb.csv', targetSizeMB: 0.5, format: 'csv' },
  { name: '1k.js', targetSizeMB: 0.01, format: 'javascript' },

  // Medium files (1MB - 5MB) - warning threshold
  { name: '1mb.json', targetSizeMB: 1, format: 'json' },
  { name: '3mb.csv', targetSizeMB: 3, format: 'csv' },
  { name: '3k.toml', targetSizeMB: 0.02, format: 'toml' },

  // Large files (5MB - 15MB) - performance degradation starts
  { name: '5mb.json', targetSizeMB: 5, format: 'json' },
  { name: '10mb.csv', targetSizeMB: 10, format: 'csv' },
  { name: '4k.html', targetSizeMB: 0.03, format: 'html' },

  // Stress test (15MB - 30MB) - approaching practical limits
  { name: '20mb.json', targetSizeMB: 20, format: 'json' },
  { name: '30mb.csv', targetSizeMB: 30, format: 'csv' },
  { name: '10k.csv', targetSizeMB: 0.5, format: 'csv' },
])

function generateJsonData(targetBytes: number): string {
  const records: any[] = []
  let currentSize = 2 // Start with [] brackets

  while (currentSize < targetBytes) {
    const record = {
      filePath: `./src/components/${Math.random().toString(36).substring(7)}.tsx`,
      relativePath: `../utils/${Math.random().toString(36).substring(7)}.ts`,
      absolutePath: `/usr/local/bin/${Math.random().toString(36).substring(7)}`,
      cssPath: `./styles/${Math.random().toString(36).substring(7)}.css`,
      imagePath: `./assets/images/${Math.random().toString(36).substring(7)}.png`,
      nested: {
        path1: `./nested/path/${Math.random()}.js`,
        path2: `../../other/${Math.random()}.json`,
      },
    }

    const recordJson = JSON.stringify(record)
    currentSize += recordJson.length + 1 // +1 for comma

    if (currentSize < targetBytes) {
      records.push(record)
    }
  }

  return JSON.stringify(records, null, 2)
}

function generateCsvData(targetBytes: number): string {
  const headers = ['id', 'path', 'relative_path', 'absolute_path', 'resource_path', 'backup_path']

  let csv = headers.join(',') + '\n'
  let currentSize = csv.length

  while (currentSize < targetBytes) {
    const row = [
      Math.floor(Math.random() * 1000000),
      `./src/components/${Math.random().toString(36).substring(7)}.tsx`,
      `../utils/${Math.random().toString(36).substring(7)}.ts`,
      `/usr/local/share/${Math.random().toString(36).substring(7)}`,
      `./assets/${Math.random().toString(36).substring(7)}.png`,
      `./backup/${Math.random().toString(36).substring(7)}.bak`,
    ]

    const rowCsv = row.join(',') + '\n'
    currentSize += rowCsv.length

    if (currentSize < targetBytes) {
      csv += rowCsv
    }
  }

  return csv
}

function generateHtmlData(targetBytes: number): string {
  let html =
    '<!DOCTYPE html>\n<html>\n<head>\n  <title>Path Extraction Test</title>\n</head>\n<body>\n'
  let currentSize = html.length

  while (currentSize < targetBytes) {
    const paths = [
      `  <link href="./styles/${Math.random()
        .toString(36)
        .substring(7)}.css" rel="stylesheet" />\n`,
      `  <script src="./scripts/${Math.random().toString(36).substring(7)}.js"></script>\n`,
      `  <img src="./images/${Math.random().toString(36).substring(7)}.png" alt="test" />\n`,
      `  <a href="./pages/${Math.random().toString(36).substring(7)}.html">Link</a>\n`,
    ]

    for (const path of paths) {
      currentSize += path.length
      if (currentSize < targetBytes) {
        html += path
      } else {
        break
      }
    }
  }

  html += '</body>\n</html>'
  return html
}

function generateTomlData(targetBytes: number): string {
  let toml = ''
  let currentSize = 0

  while (currentSize < targetBytes) {
    const section = `[package_${Math.random().toString(36).substring(7)}]\n`
    const pathLine = `path = "./src/${Math.random().toString(36).substring(7)}.rs"\n`
    const configLine = `config = "../config/${Math.random().toString(36).substring(7)}.toml"\n\n`

    const block = section + pathLine + configLine
    currentSize += block.length

    if (currentSize < targetBytes) {
      toml += block
    }
  }

  return toml
}

function generateJavaScriptData(targetBytes: number): string {
  let js = ''
  let currentSize = 0

  while (currentSize < targetBytes) {
    const imports = [
      `import { Component } from './components/${Math.random().toString(36).substring(7)}';\n`,
      `import utils from '../utils/${Math.random().toString(36).substring(7)}.js';\n`,
      `require('./config/${Math.random().toString(36).substring(7)}.json');\n`,
      `const path = './assets/${Math.random().toString(36).substring(7)}.png';\n`,
    ]

    for (const line of imports) {
      currentSize += line.length
      if (currentSize < targetBytes) {
        js += line
      } else {
        break
      }
    }
  }

  return js
}

function generateData(format: string, targetBytes: number): string {
  switch (format) {
    case 'json':
      return generateJsonData(targetBytes)
    case 'csv':
      return generateCsvData(targetBytes)
    case 'html':
      return generateHtmlData(targetBytes)
    case 'toml':
      return generateTomlData(targetBytes)
    case 'javascript':
      return generateJavaScriptData(targetBytes)
    default:
      throw new Error(`Format ${format} not implemented yet`)
  }
}

function formatBytes(bytes: number): string {
  if (bytes < 1024) return `${bytes}B`
  if (bytes < 1024 * 1024) return `${(bytes / 1024).toFixed(2)}KB`
  return `${(bytes / 1024 / 1024).toFixed(2)}MB`
}

function runBenchmarks(): string {
  console.log('\nüìä Running performance benchmarks...\n')
  try {
    const output = execSync('bun test ./src/extraction/performance.bench.ts', {
      encoding: 'utf-8',
      cwd: process.cwd(),
    })
    console.log('‚úÖ Benchmarks completed!\n')
    return output
  } catch (error: any) {
    console.error('‚ùå Benchmark failed:', error.message)
    throw error
  }
}

function extractPerformanceReport(benchmarkOutput: string): string {
  const startMarker = '# Paths-LE Performance Test Results'
  const endMarker = '='.repeat(80)

  const startIdx = benchmarkOutput.indexOf(startMarker)
  const endIdx = benchmarkOutput.lastIndexOf(endMarker)

  if (startIdx === -1 || endIdx === -1) {
    throw new Error('Could not find performance report in benchmark output')
  }

  return benchmarkOutput.substring(startIdx, endIdx).trim()
}

function updatePerformanceMd(report: string) {
  console.log('üìù Updating docs/PERFORMANCE.md...')
  const perfMdPath = join(process.cwd(), 'docs', 'PERFORMANCE.md')
  writeFileSync(perfMdPath, report, 'utf-8')
  console.log('‚úÖ docs/PERFORMANCE.md updated!\n')
}

function updateReadmeTable(benchmarkOutput: string) {
  console.log('üìù Updating README.md performance table...')

  // Extract key metrics from benchmark output
  const metrics: Record<string, any> = {}
  const lines = benchmarkOutput.split('\n')

  for (const line of lines) {
    if (
      line.includes('| JSON |') ||
      line.includes('| CSV |') ||
      line.includes('| HTML |') ||
      line.includes('| TOML |') ||
      line.includes('| JavaScript |')
    ) {
      const parts = line
        .split('|')
        .map((s) => s.trim())
        .filter(Boolean)
      if (parts.length >= 7) {
        const [format, file, size, , time, extracted, throughput] = parts
        if (!metrics[format]) {
          metrics[format] = []
        }
        metrics[format].push({ file, size, time, extracted, throughput })
      }
    }
  }

  // Build performance table content (between markers)
  const perfTableContent = `
Paths-LE is built for speed and handles files from 100KB to 30MB+. See [detailed benchmarks](docs/PERFORMANCE.md).

| Format   | File Size | Throughput      | Duration | Memory | Tested On     |
| -------- | --------- | --------------- | -------- | ------ | ------------- |
${generateReadmeRows(metrics)}

**Real-World Performance**: Tested with actual data up to 30MB (practical limit: 1MB warning, 10MB error threshold)  
**Performance Monitoring**: Built-in real-time tracking with configurable thresholds  
**Full Metrics**: [docs/PERFORMANCE.md](docs/PERFORMANCE.md) ‚Ä¢ Test Environment: macOS, Bun 1.2.22, Node 22.x
`.trim()

  // Update README using markers
  const readmePath = join(process.cwd(), 'README.md')
  let readme = readFileSync(readmePath, 'utf-8')

  // Look for marker comments (invisible in rendered markdown)
  const startMarker = '<!-- PERFORMANCE_START -->'
  const endMarker = '<!-- PERFORMANCE_END -->'

  const startIdx = readme.indexOf(startMarker)
  const endIdx = readme.indexOf(endMarker)

  if (startIdx !== -1 && endIdx !== -1) {
    // Replace content between markers
    readme =
      readme.substring(0, startIdx + startMarker.length) +
      '\n\n' +
      perfTableContent +
      '\n\n' +
      readme.substring(endIdx)
    writeFileSync(readmePath, readme, 'utf-8')
    console.log('‚úÖ README.md updated!\n')
  } else {
    console.warn('‚ö†Ô∏è  Performance markers not found in README.md')
    console.warn('   Add these markers around your performance section:')
    console.warn('   <!-- PERFORMANCE_START -->')
    console.warn('   <!-- PERFORMANCE_END -->')
    console.warn('   Falling back to section-based replacement...\n')

    // Fallback to old method
    const perfSectionStart = readme.indexOf('## ‚ö° Performance')
    const nextSectionStart = readme.indexOf('\n## ', perfSectionStart + 1)

    if (perfSectionStart !== -1 && nextSectionStart !== -1) {
      readme =
        readme.substring(0, perfSectionStart) +
        '## ‚ö° Performance\n\n' +
        perfTableContent +
        '\n\n' +
        readme.substring(nextSectionStart)
      writeFileSync(readmePath, readme, 'utf-8')
      console.log('‚úÖ README.md updated (using fallback method)\n')
    } else {
      console.error('‚ùå Could not find performance section in README.md\n')
    }
  }
}

function generateReadmeRows(metrics: Record<string, any[]>): string {
  const rows: string[] = []

  // HTML rows
  if (metrics.HTML && metrics.HTML[0]) {
    const m = metrics.HTML[0]
    rows.push(`| **HTML** | 4K lines  | ${m.throughput} | ~${m.time} | < 1MB  | Apple Silicon |`)
  }

  // CSV rows
  if (metrics.CSV) {
    for (const m of metrics.CSV.slice(0, 4)) {
      const throughput = m.throughput.replace(/,/g, '')
      const memory = m.size.includes('10K')
        ? '~37MB'
        : m.size.includes('10MB')
        ? '~55MB'
        : m.size.includes('3MB')
        ? '~27MB'
        : '< 1MB'
      rows.push(`| **CSV**  | ${m.size} | ${throughput} | ~${m.time} | ${memory} | Apple Silicon |`)
    }
  }

  // TOML rows
  if (metrics.TOML && metrics.TOML[0]) {
    const m = metrics.TOML[0]
    rows.push(`| **TOML** | 3K lines  | ${m.throughput} | ~${m.time} | < 1MB  | Apple Silicon |`)
  }

  // JSON rows
  if (metrics.JSON) {
    for (const m of metrics.JSON.slice(0, 4)) {
      const throughput = m.throughput.replace(/,/g, '')
      const memory = m.size.includes('20MB') ? '~56MB' : '< 1MB'
      rows.push(`| **JSON** | ${m.size} | ${throughput} | ~${m.time} | ${memory} | Apple Silicon |`)
    }
  }

  return rows.join('\n')
}

function main() {
  console.log('üöÄ Complete Performance Pipeline for paths-le\n')
  console.log('='.repeat(60) + '\n')

  // Step 1: Generate test data
  console.log('üì¶ STEP 1: Generating performance test data files...\n')
  const perfDir = join(process.cwd(), 'src', 'extraction', '__performance__')

  for (const spec of FILE_SPECS) {
    const filePath = join(perfDir, spec.name)
    const targetBytes = spec.targetSizeMB * 1024 * 1024

    try {
      console.log(`  ‚è≥ Creating ${spec.name} (target: ${spec.targetSizeMB}MB)...`)
      const data = generateData(spec.format, targetBytes)
      writeFileSync(filePath, data, 'utf-8')

      const actualSize = Buffer.byteLength(data, 'utf-8')
      console.log(`  ‚úÖ Created ${spec.name} (${formatBytes(actualSize)})`)
    } catch (error) {
      console.error(`  ‚ùå Failed to create ${spec.name}:`, error)
    }
  }

  console.log('\n‚úÖ Test data generation complete!\n')

  // Step 2: Run benchmarks
  console.log('='.repeat(60) + '\n')
  console.log('üî¨ STEP 2: Running performance benchmarks...\n')
  const benchmarkOutput = runBenchmarks()

  // Step 3: Extract and save performance report
  console.log('='.repeat(60) + '\n')
  console.log('üìä STEP 3: Updating documentation...\n')
  try {
    const report = extractPerformanceReport(benchmarkOutput)
    updatePerformanceMd(report)
  } catch (error: any) {
    console.error('‚ö†Ô∏è  Could not extract performance report:', error.message)
  }

  // Step 4: Update README
  try {
    updateReadmeTable(benchmarkOutput)
  } catch (error: any) {
    console.error('‚ö†Ô∏è  Could not update README:', error.message)
  }

  console.log('='.repeat(60) + '\n')
  console.log('üéâ Complete! All performance metrics updated.\n')
  console.log('üìã Summary:')
  console.log('  ‚úÖ Test data generated')
  console.log('  ‚úÖ Benchmarks executed')
  console.log('  ‚úÖ docs/PERFORMANCE.md updated')
  console.log('  ‚úÖ README.md updated\n')
}

main()
